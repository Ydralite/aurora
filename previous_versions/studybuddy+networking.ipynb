{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53cb8075-be0c-452d-a1d0-0eeaec457a03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import json\n",
    "import openai\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# chatOpenAI within langchain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "# prompt template refers to a reproducible way to generate a prompt\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# LangChain for question answering over a list of documents\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Load data from a source as Document's. A Document is a piece of text and associated metadata.\n",
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "# DocArrayInMemorySearch is a document index provided by Docarray that stores documents in memory\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "\n",
    "#takes care of storing embedded data and performing vector search for you\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "#pdf loader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# QA evaluator\n",
    "from langchain.evaluation.qa import QAGenerateChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500b5fb-3a37-4815-bd5c-f84b01e389e3",
   "metadata": {},
   "source": [
    "# environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5977ef7b-8006-42d8-9c9e-f1b83f528bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "CONFIG_FILE = \"config.json\"\n",
    "\n",
    "# Load Config File\n",
    "with open(join(CURRENT_PATH, CONFIG_FILE)) as file:\n",
    "    # Load the JSON data\n",
    "    config = json.load(file)\n",
    "\n",
    "# Environmental Variables\n",
    "AZURE_OPENAI_KEY = config['AZURE_OPENAI_KEY']\n",
    "AZURE_OPENAI_ENDPOINT = config['AZURE_OPENAI_ENDPOINT']\n",
    "AZURE_ENGINE_NAME = config['AZURE_ENGINE_NAME']\n",
    "AZURE_ADA_NAME = config['AZURE_ADA_NAME']\n",
    "AZURE_ADA_ENDPOINT = config['AZURE_ADA_ENDPOINT']\n",
    "AZURE_ADA_KEY = config['AZURE_ADA_KEY']\n",
    "\n",
    "# OpenAI ADA API embeddings \n",
    "openai_ada_key = AZURE_ADA_KEY\n",
    "openai_ada_base = AZURE_ADA_ENDPOINT\n",
    "openai_ada_deployment = AZURE_ADA_NAME\n",
    "openai_api_type = 'azure'\n",
    "openai_api_key = AZURE_OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b7d109-e9ae-4a4e-aef6-eb7f7f0243ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai=AzureChatOpenAI(openai_api_base=AZURE_OPENAI_ENDPOINT\n",
    "         ,openai_api_key=AZURE_OPENAI_KEY\n",
    "         ,openai_api_type='azure'\n",
    "         ,openai_api_version=\"2023-05-15\"\n",
    "         ,deployment_name =AZURE_ENGINE_NAME\n",
    "         ,model = \"gpt-3.5-turbo\"\n",
    "         ,temperature=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e2740a-a869-4d71-88b1-6d0af24401e3",
   "metadata": {},
   "source": [
    "# load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7aba684-a5f7-4462-81dd-45a32a69d6a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = 'onboarding docs'\n",
    "FILE = 'Valve_Handbook_LowRes-1-10.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f5f8445-d3b1-4ecc-9de3-cc7fe44de928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load PDF File\n",
    "loader = PyPDFLoader(join(PATH,FILE))\n",
    "data_handbook = loader.load()\n",
    "\n",
    "text_splitter= CharacterTextSplitter(\n",
    "    separator='\\n',\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")\n",
    "data_handbook=text_splitter.split_documents(data_handbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fca333c-ce07-4cd1-9c99-5bfa115d4741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = 'onboarding docs'\n",
    "FILE = 'chart_valve.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "906b1e4b-a5d0-4cc6-9697-5d8992ebe800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load JSON\n",
    "import json\n",
    "chart_file = json.load(open(join(PATH,FILE)))\n",
    "chart_file=json.dumps(chart_file).split(\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1e0d20-82a4-42e4-a90d-2ad220577dde",
   "metadata": {
    "tags": []
   },
   "source": [
    "# embedding & vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8929ff8f-706f-42ce-8523-8b4db8e3d4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding=OpenAIEmbeddings(openai_api_key=openai_ada_key\n",
    "                              , openai_api_base = openai_ada_base\n",
    "                              , deployment = openai_ada_deployment\n",
    "                              , openai_api_type = openai_api_type\n",
    "                              ,chunk_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06c83aba-335a-4992-aaf7-7d11e58784ee",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "persist_directory='docs/chroma'\n",
    "vectordb_chart=Chroma.from_texts(\n",
    "    texts=chart_file,\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6bdc2745-6524-4180-98e2-af9990c02410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever=vectordb_chart.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7045b7b6-7ef1-4359-bd8e-3515b786452f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(vectordb_chart._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17cb691f-c42d-4bcf-bdea-6c2d39231e18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    }
   ],
   "source": [
    "persist_directory='docs/chroma'\n",
    "vectordb_handbook=Chroma.from_documents(\n",
    "    documents=data_handbook,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37c799b-f009-4502-b7a3-458175a830e6",
   "metadata": {},
   "source": [
    "# retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b962ab4-8f1a-4af4-b682-2e5cf1538864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "handbook_retriever = vectordb_handbook.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98fc066-4b1b-41a3-acd9-3474aabfbcdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chart_retriever = vectordb_chart.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d95115-1a52-4656-b6e1-39f027ce2db0",
   "metadata": {},
   "source": [
    "# memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b3f8190-a9e2-46ae-a6ee-1e648189b26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "memory_buddy = ConversationSummaryMemory(memory_key=\"chat_history\", llm=AzureChatOpenAI(openai_api_base=AZURE_OPENAI_ENDPOINT\n",
    "         ,openai_api_key=AZURE_OPENAI_KEY\n",
    "         ,openai_api_type='azure'\n",
    "         ,openai_api_version=\"2023-05-15\"\n",
    "         ,deployment_name =AZURE_ENGINE_NAME\n",
    "         ,model = \"gpt-3.5-turbo\"\n",
    "         ,temperature=0.1\n",
    "    ), return_messages=True, input_key=\"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa322d98-429a-49fa-b2c6-1e2dba9f18fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "memory_network = ConversationSummaryMemory(memory_key=\"chat_history\", llm=AzureChatOpenAI(openai_api_base=AZURE_OPENAI_ENDPOINT\n",
    "         ,openai_api_key=AZURE_OPENAI_KEY\n",
    "         ,openai_api_type='azure'\n",
    "         ,openai_api_version=\"2023-05-15\"\n",
    "         ,deployment_name =AZURE_ENGINE_NAME\n",
    "         ,model = \"gpt-3.5-turbo\"\n",
    "         ,temperature=0.1\n",
    "    ), return_messages=True, input_key=\"question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96b02af-90f0-46de-a433-18d16d0508f9",
   "metadata": {},
   "source": [
    "# qa chain type stuff - BEST BABY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c613dc-1a06-4faf-8811-eac044d3724f",
   "metadata": {},
   "source": [
    "## study buddy btch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cc76b35-ca45-448d-8f9e-580f45fb8566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Return the answer together with the source (document and pages).\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_sb = load_qa_chain(ai, chain_type=\"stuff\", prompt=PROMPT, memory=memory_buddy, output_key=\"topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3310991c-95f9-45fe-94e1-03c5d3d24150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': \"I'm sorry, but I don't have enough information to recap the document based on the given context.\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_sb({\"input_documents\": handbook_retriever.get_relevant_documents(query), \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aae935-5d6d-40b8-948c-5ce3b4335ab8",
   "metadata": {},
   "source": [
    "## networking mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fb35581-8b2b-4fd9-95b2-6557fd7258bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Given the following information regarding company workers, give up to three recommendations about the best person to talk about:\n",
    "Only recommend someone if you are confident they are a relevant person for the topic and if the topic is clear. Otherwise, don't recommend anyone.\n",
    " \n",
    "Context about company workers:{context}\n",
    "\n",
    "Topic: {question}\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_nw = load_qa_chain(ai, chain_type=\"stuff\", prompt=PROMPT, memory=memory_network, output_key=\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf979e65-e026-41c8-8982-fc8dd0358a57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query=\"Who knows about sandwiches?\"#\"Does Valve have data science models?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0161147e-6d82-4bac-b7b1-85f7fbcdeb14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': 'Based on the given information, I cannot recommend anyone to talk about the topic as there is not enough information provided to determine a relevant person.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_nw({\"input_documents\": chart_retriever.get_relevant_documents(query), \"question\": memory_buddy.chat_memory.messages[-1].content}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a6b89-86f8-4217-b10d-b04dfae7a15d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory_buddy.chat_memory.messages[-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561239c6-689a-451d-a387-c009ca2d0598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory_network.chat_memory.messages[-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05c66c9-b584-47a1-87e9-7e45e728295c",
   "metadata": {},
   "source": [
    "# alternatives that didn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0a3c883-a60e-4681-9b7f-591091139916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Return the answer together with the source (document and pages).\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "QUESTION_PROMPT = PromptTemplate(\n",
    "    template=question_prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "combine_prompt_template = \"\"\"Given the following information regarding company workers, give three recommendations about the best person to talk about a given topic.\n",
    "\n",
    "{chart}\n",
    "\n",
    "Topic: {summaries}\"\"\"\n",
    "COMBINE_PROMPT = PromptTemplate(\n",
    "    template=combine_prompt_template, input_variables=[\"summaries\", \"chart\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "239448fb-677d-4f86-a40e-45d266c850c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = load_qa_chain(ai, chain_type=\"map_reduce\", question_prompt=QUESTION_PROMPT, combine_prompt=COMBINE_PROMPT, return_map_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca2ee8c5-a371-4594-9494-34dcd938b71c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result=chain({\"input_documents\": vectordb_handbook.similarity_search(query,k=3), \"question\": query, \"chart\":vectordb_chart.similarity_search(query,k=3)}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a10f89e9-c0f3-45ae-8aa8-ef7c480a3626",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['According to the given context, it is not specified what exactly an employee should do on their first day at Valve.'],\n",
       " 'output_text': \"Based on the given information, here are three recommendations for the best person to talk to about the topic of what an employee should do on their first day at Valve:\\n\\n1. Linda Walker: As a Public Relations Specialist, Linda manages Valve's public image and coordinates communication strategies. She may have insights into the onboarding process and can provide information on what new employees typically do on their first day.\\n\\n2. Rachel Thompson: Being a System Administrator, Rachel is responsible for maintaining and troubleshooting Valve's server infrastructure. She may have knowledge of the technical aspects of employee onboarding, such as setting up accounts, accessing systems, and familiarizing new hires with the company's technology.\\n\\n3. Michelle Green: As the Art Director, Michelle oversees the art department and guides the visual style of Valve's games. Although her role may not directly involve onboarding, she may have a broader understanding of the company's culture and values, which could provide insights into what new employees can expect on their first day.\\n\\nNote: While these individuals may not have specific information about what an employee should do on their first day, they can provide valuable perspectives based on their roles and expertise within the company.\"}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c71e58ac-e737-4590-ac5a-d328ad5d1f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x0000023EBEF4D090>, search_type='similarity', search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb_handbook.as_retriever(search_kwargs={'k':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5220c16-bc0f-4996-b6b0-c35ac92e6329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SequentialChain\n__root__\n  Missing required input keys: {'input_documents'}, only had {'context', 'question', 'chart'} (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m full_chain\u001b[38;5;241m=\u001b[39m\u001b[43mSequentialChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mchain_sb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_nw\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchart\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpeople\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv\\Lib\\site-packages\\langchain\\load\\serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv\\Lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for SequentialChain\n__root__\n  Missing required input keys: {'input_documents'}, only had {'context', 'question', 'chart'} (type=value_error)"
     ]
    }
   ],
   "source": [
    "full_chain=SequentialChain(chains=[chain_sb, chain_nw],input_variables=[\"context\", \"question\", \"chart\"],output_variables=[\"topic\", \"people\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ceaf9a63-f7a2-4d79-be20-4d578f6e0a85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'input'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat should I do on my first day?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mfull_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_documents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectordb_handbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:220\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    187\u001b[0m     inputs: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Any],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m     include_run_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    194\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m    195\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m            `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     callback_manager \u001b[38;5;241m=\u001b[39m CallbackManager\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[0;32m    222\u001b[0m         callbacks,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[0;32m    230\u001b[0m     new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:374\u001b[0m, in \u001b[0;36mChain.prep_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    372\u001b[0m     external_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mload_memory_variables(inputs)\n\u001b[0;32m    373\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexternal_context)\n\u001b[1;32m--> 374\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:132\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    130\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Missing some input keys: {'input'}"
     ]
    }
   ],
   "source": [
    "query=\"What should I do on my first day?\"\n",
    "full_chain({\"input_documents\": vectordb_handbook.similarity_search(query,k=3), \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "09f64be6-a0f2-411f-b2d9-af58d70c23b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': \"1. Gabe Newell - as the CEO and co-founder of Valve, he would have a deep understanding of the company's structure and values, as well as the long-term goals and vision for the company.\\n\\n2. Sarah Thompson - as the Human Resources Manager, she would have a thorough understanding of the company's culture and values, as well as the hiring process and how new employees are onboarded into the company.\\n\\n3. Michelle Clark - as a Project Manager, she would have experience working within the flat structure of Valve and could provide insight into how employees prioritize their work and collaborate on projects without traditional management structures.\"}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"The handbook for new employees at Valve describes the company as having a flat structure, where there is no management and nobody reports to anybody else. Employees are encouraged to pick their own projects and are responsible for prioritizing their own work. The company is described as being focused on creating a place where talented individuals are empowered to put their best work into the hands of millions of people, with very little in their way. The handbook also emphasizes the importance of hiring and the responsibility of all employees to focus on the long-term goals of the company\"\n",
    "chain({\"input_documents\": vectordb.similarity_search(query,k=3), \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "faa30344-a268-445c-9363-acde6254e058",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human asks the AI about the most important information in a document, and the AI responds that the unique structure and culture of Valve, as described in their handbook for new employees, is the most important information. The handbook emphasizes a flat organization where employees have freedom to choose their own projects and make decisions without traditional management. The company is focused on empowering talented individuals to put their best work into the hands of millions of people, with very little in their way. According to the AI, the first thing to do when joining Valve is to read the \"Handbook for New Employees.\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8903ea3-713a-4946-83bb-15b29c535279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the most important information in the document?', additional_kwargs={}, example=False),\n",
       " AIMessage(content=\"The most important information in the document is the unique structure and culture of Valve as a flat organization where employees have the freedom to choose their own projects and make decisions without traditional management. This is emphasized throughout the handbook and is a key aspect of Valve's approach to work. (Source: Valve Handbook for New Employees, various pages)\", additional_kwargs={}, example=False),\n",
       " HumanMessage(content='How is it to work at Valve?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Answer: The handbook for new employees at Valve describes the company as having a flat structure, where there is no management and nobody reports to anybody else. Employees are encouraged to pick their own projects and are responsible for prioritizing their own work. The company is described as being focused on creating a place where talented individuals are empowered to put their best work into the hands of millions of people, with very little in their way. The handbook also emphasizes the importance of hiring and the responsibility of all employees to focus on the long-term goals of the company. Source: Valve: Handbook for New Employees, pages vii-ix, 1-2, 7-11.', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='What is the first thing to do when joining Valve?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The first thing to do when joining Valve is to read the \"Handbook for New Employees.\" (Source: \"Handbook for New Employees\" Preface, page vii)', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4838928-1c8f-4aaf-a7b4-fb5f4aa1eac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c81912-1617-4d07-873e-f086834ca5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
